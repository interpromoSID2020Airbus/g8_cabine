{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clonage dans 'ProjetInterpromo2020G8'...\r\n",
      "remote: Enumerating objects: 17, done.\u001b[K\r\n",
      "remote: Counting objects:   5% (1/17)\u001b[K\r",
      "remote: Counting objects:  11% (2/17)\u001b[K\r",
      "remote: Counting objects:  17% (3/17)\u001b[K\r",
      "remote: Counting objects:  23% (4/17)\u001b[K\r",
      "remote: Counting objects:  29% (5/17)\u001b[K\r",
      "remote: Counting objects:  35% (6/17)\u001b[K\r",
      "remote: Counting objects:  41% (7/17)\u001b[K\r",
      "remote: Counting objects:  47% (8/17)\u001b[K\r",
      "remote: Counting objects:  52% (9/17)\u001b[K\r",
      "remote: Counting objects:  58% (10/17)\u001b[K\r",
      "remote: Counting objects:  64% (11/17)\u001b[K\r",
      "remote: Counting objects:  70% (12/17)\u001b[K\r",
      "remote: Counting objects:  76% (13/17)\u001b[K\r",
      "remote: Counting objects:  82% (14/17)\u001b[K\r",
      "remote: Counting objects:  88% (15/17)\u001b[K\r",
      "remote: Counting objects:  94% (16/17)\u001b[K\r",
      "remote: Counting objects: 100% (17/17)\u001b[K\r",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Compressing objects:   6% (1/15)\u001b[K\r",
      "remote: Compressing objects:  13% (2/15)\u001b[K\r",
      "remote: Compressing objects:  20% (3/15)\u001b[K\r",
      "remote: Compressing objects:  26% (4/15)\u001b[K\r",
      "remote: Compressing objects:  33% (5/15)\u001b[K\r",
      "remote: Compressing objects:  40% (6/15)\u001b[K\r",
      "remote: Compressing objects:  46% (7/15)\u001b[K\r",
      "remote: Compressing objects:  53% (8/15)\u001b[K\r",
      "remote: Compressing objects:  60% (9/15)\u001b[K\r",
      "remote: Compressing objects:  66% (10/15)\u001b[K\r",
      "remote: Compressing objects:  73% (11/15)\u001b[K\r",
      "remote: Compressing objects:  80% (12/15)\u001b[K\r",
      "remote: Compressing objects:  86% (13/15)\u001b[K\r",
      "remote: Compressing objects:  93% (14/15)\u001b[K\r",
      "remote: Compressing objects: 100% (15/15)\u001b[K\r",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\r\n",
      "Réception d'objets:   0% (1/443)\r",
      "Réception d'objets:   1% (5/443)\r",
      "Réception d'objets:   2% (9/443)\r",
      "Réception d'objets:   3% (14/443)\r",
      "Réception d'objets:   4% (18/443)\r",
      "Réception d'objets:   5% (23/443)\r",
      "Réception d'objets:   6% (27/443)\r",
      "Réception d'objets:   7% (32/443)\r",
      "Réception d'objets:   8% (36/443)\r",
      "Réception d'objets:   9% (40/443)\r",
      "Réception d'objets:  10% (45/443)\r",
      "Réception d'objets:  11% (49/443)\r",
      "Réception d'objets:  12% (54/443)\r",
      "Réception d'objets:  13% (58/443)\r",
      "Réception d'objets:  14% (63/443)\r",
      "Réception d'objets:  15% (67/443)\r",
      "Réception d'objets:  16% (71/443)\r",
      "Réception d'objets:  17% (76/443)\r",
      "Réception d'objets:  18% (80/443)\r",
      "Réception d'objets:  19% (85/443)\r",
      "Réception d'objets:  20% (89/443)\r",
      "Réception d'objets:  21% (94/443)\r",
      "Réception d'objets:  22% (98/443)\r",
      "Réception d'objets:  23% (102/443)\r",
      "Réception d'objets:  24% (107/443)\r",
      "Réception d'objets:  25% (111/443)\r",
      "Réception d'objets:  26% (116/443)\r",
      "Réception d'objets:  27% (120/443)\r",
      "Réception d'objets:  28% (125/443)\r",
      "Réception d'objets:  29% (129/443)\r",
      "Réception d'objets:  30% (133/443)\r",
      "Réception d'objets:  31% (138/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  32% (142/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  33% (147/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  34% (151/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  35% (156/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  36% (160/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  37% (164/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  38% (169/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  39% (173/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  40% (178/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  41% (182/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  42% (187/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  42% (189/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  43% (191/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  44% (195/443), 1.34 Mio | 2.67 Mio/s\r",
      "Réception d'objets:  45% (200/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  46% (204/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  47% (209/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  48% (213/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  49% (218/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  50% (222/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  51% (226/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  52% (231/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  53% (235/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  54% (240/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  55% (244/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  56% (249/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  57% (253/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  58% (257/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  59% (262/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  60% (266/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  61% (271/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  62% (275/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  63% (280/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  64% (284/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  65% (288/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  66% (293/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  67% (297/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  68% (302/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  69% (306/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  70% (311/443), 4.39 Mio | 4.36 Mio/s\r",
      "Réception d'objets:  71% (315/443), 4.39 Mio | 4.36 Mio/s\r"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vincentnam/ProjetInterpromo2020G8.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Fri Jan 3 13:28:13 CET 2019\n",
    "Group 8\n",
    "@authors: DANG Vincent-Nam\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pipeline \n",
    "\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "# TODO :\n",
    "#  - Tests unitaires et tests intégrations : test pipeline\n",
    "#  (run_pipeline), levées d'erreur, etc...\n",
    "#  - Traduire les commentaires en anglais (si besoin ?)\n",
    "#  - Mettre à jour le pipeline pour prendre en compte des resultats\n",
    "#    auxiliaires nécessaire pour le traitement suivant\n",
    "#  - Gestion des hints plus formellement\n",
    "#  - Gestion de l'héritage des docstrings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-f6ab7ac6e69f>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-f6ab7ac6e69f>\"\u001b[0;36m, line \u001b[0;32m78\u001b[0m\n\u001b[0;31m    }temp_bar.jpg\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ImageUtil():\n",
    "    def __init__(self, input_path, image_name, image=None):\n",
    "        self.input_path = input_path\n",
    "        self.image_name = image_name\n",
    "        if image is  None:\n",
    "            self.image_pil = Image.open(self.input_path + self.image_name)\n",
    "            self.image_plt = plt.imread(self.input_path + self.image_name)\n",
    "        else:\n",
    "            self.image_pil = image\n",
    "            self.image_plt = image\n",
    "            self.image = image\n",
    "        \n",
    "        self.sort_pixel = {}\n",
    "        \n",
    "    def sort_pixel(self):\n",
    "        \"\"\"\n",
    "            Sort the pixel value by number of occurences that they appear in the image\n",
    "        \"\"\"\n",
    "        by_color = defaultdict(int)\n",
    "        for pixel in self.image_pil.getdata():\n",
    "            by_color[pixel] += 1\n",
    "\n",
    "        self.sort_pixel =  {k: v for k, v in sorted(by_color.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    def visualisation(self, x_size, y_size):\n",
    "        \"\"\"\n",
    "            Show the image\n",
    "            params : \n",
    "                x_size - width of the plot\n",
    "                y_size - height of the plot\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(x_size,y_size))\n",
    "        if self.image is not None:\n",
    "            plt.imshow(self.image.astype('uint8'))\n",
    "        else:\n",
    "            plt.imshow(self.image_plt.astype('uint8'))\n",
    "\n",
    "    def to_rgb(self):\n",
    "        \"\"\"\n",
    "            Convert the image to an RGB format from a BGR format\n",
    "        \"\"\"\n",
    "        return cv.cvtColor(self.image_plt, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    def to_gray(self):\n",
    "        \"\"\"\n",
    "            Convert the image to a GRAY format from a BGR format\n",
    "        \"\"\"\n",
    "        return cv.cvtColor(self.image_plt, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    def save_image(self, output_path):\n",
    "        \"\"\"\n",
    "            Save the image to specific location\n",
    "            params : \n",
    "                output_path - where the image will be saved\n",
    "        \"\"\"\n",
    "        plt.imsave(output_path + self.image_name, self.image_plt.astype('uint8'))\n",
    "\n",
    "class Colour():\n",
    "    COLOURS = {\n",
    "        'LAYOUT_SEATGURU': {\n",
    "            'jpg':{\n",
    "                \"blue\":[139, 168, 198],\n",
    "                \"yellow\": [247, 237, 86],\n",
    "                \"exit\": [222, 111, 100],\n",
    "                \"green\": [89, 185, 71],\n",
    "                \"red_bad_seat\": [244, 121, 123],\n",
    "                \"blue_seat_crew\": [140,169,202],\n",
    "                \"baby\": [184,214,240]\n",
    "            },\n",
    "            'png':{\n",
    "                \"blue\":[41,182,209],\n",
    "                \"yellow\": [251,200,2],\n",
    "                \"exit\": [190,190,190],\n",
    "                \"green\": [41,209,135],\n",
    "                \"red_bad_seat\": [226,96,82],\n",
    "                \"blue_seat_crew\": [41,182,209],\n",
    "                \"baby\": [197,197,197]\n",
    "            }temp_bar.jpg\n",
    "        },\n",
    "        'LAYOUT_SEATMAESTRO': {\n",
    "            'png': {\n",
    "                \"blue\":[81,101,181],\n",
    "                \"exit\": [1,120,175],\n",
    "                \"green\": [120,189,198],\n",
    "                \"red_bad_seat\": [207,90,150],\n",
    "                \"blue_seat_crew\": [138,165,190] \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, input_path, layout, image_name):\n",
    "        self.input_path = input_path\n",
    "        self.layout = layout\n",
    "        self.image_name = image_name\n",
    "        self.image_extension = image_name.split('.')[-1]\n",
    "        \n",
    "        self.image = plt.imread(self.input_path + self.layout + '/' + self.image_name)\n",
    "        self.image_util = ImageUtil(self.input_path + self.layout + '/', self.image_name)\n",
    "        \n",
    "    def colour_detection(self, colours, epsilon, rgb_len, colour_mode, default_colour):\n",
    "        \"\"\"\n",
    "            This function will detect the colour and will do some pre-process on it\n",
    "            params : \n",
    "                colours : a dictionnary with a ltemp_bar.jpgist of specified colours\n",
    "                epsilon : threshold that allows to consider a colour from another one as close\n",
    "                rgb_len : only take the 3 first elements from pixel (RGB norm)\n",
    "                colour_mode : \n",
    "                    if true : it means that if we consider a colour from the image close \n",
    "                    to a colour from the \"colours\" dict, then it will replace the colour by the one in the dict. \n",
    "                    if false : it means that if we consider a colour from the image close \n",
    "                    to a colour from the \"colours\" dict, then it will replace the colour by the default color value.\n",
    "                default_color : default color value that a pixel has to take\n",
    "        \"\"\"\n",
    "        # make a copy to avoid to erase the original image\n",
    "        img_copy = self.image_util.to_rgb()\n",
    "\n",
    "        # for each line we get the pixel value\n",
    "        for i, line in enumerate(self.image):\n",
    "            for j, pixel in enumerate(line):\n",
    "                # Get only 3 first value corresponding to R,G,B\n",
    "                pixel = [int(val) if val >  1.0 else int(val*255) for val in self.image[i][j]][:rgb_len]\n",
    "\n",
    "                # if we want to show a specific colour\n",
    "                if colour_mode:\n",
    "                    # default value\n",
    "                    img_copy[i][j] = default_colour\n",
    "\n",
    "                    # for each colour we change the pixel value if we find the same colour\n",
    "                    for colour in colours.values():\n",
    "                        if sum([1 if abs(p-b) < epsilon else 0 for p,b in zip(pixel, colour)]) == rgb_len:\n",
    "                            img_copy[i][j] = coltemp_bar.jpgour\n",
    "\n",
    "                # if we want to hide a colour by a default value\n",
    "                else:\n",
    "                    # default value\n",
    "                    img_copy[i][j] = pixel\n",
    "\n",
    "                    # for each recognized colour, we change it by the default value\n",
    "                    for colour in colours.values():\n",
    "                            if sum([1 if abs(p-b) < epsilon else 0 for p,b in zip(pixel, colour)]) == rgb_len:\n",
    "                                img_copy[i][j] = default_colour\n",
    "        return img_copy\n",
    "\n",
    "\n",
    "    def colour_pipeline(self, colours = {}, epsilon = 20, colour_mode = True, \n",
    "                    default_colour = [0, 0, 0], rgb_len = 3):\n",
    "        \"\"\"\n",
    "            Call colour_detection function in order to pre-process colours in image\n",
    "            params : \n",
    "                colours : a dictionnary with a list of specified colours\n",
    "                epsilon : threshold that allows to consider a colour from another one as close\n",
    "                rgb_len : only take the 3 first elements from pixel (RGB norm)\n",
    "                colour_mode : \n",
    "                    - if true (highlight colours in \"colours\" dict by standardize it) : it means that \n",
    "                    if we consider a colour from the image close to a colour from the \"colours\" dict, \n",
    "                    then it will replace the colour by the one in the dict. \n",
    "                    - if false (remove colours in \"colours\" dict by the default one) : it means that \n",
    "                    if we consider a colour from the image close to a colour from the \"colours\" dict, \n",
    "                    then it will replace the colour by the default color value.\n",
    "                default_color : default color value that a pixel has to take\n",
    "        \"\"\"\n",
    "        # if colours is empty we take the default value\n",
    "        if not bool(colours): colours = COLOURS[self.layout][self.image_extension]\n",
    "            \n",
    "        # get the image result from colour decection pre-process wanted\n",
    "        image_res = self.colour_detection(colours, epsilon, rgb_len, colour_mode, default_colour)\n",
    "\n",
    "        return image_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# SIEGE \n",
    "\n",
    "\n",
    "# def coord_pattern_finder(image, template, threshold):\n",
    "#     \"\"\"\n",
    "#     input:\n",
    "#         image : image plane cv2.imread() black and white\n",
    "#         template : image pattern cv2.imread()\n",
    "#         threshold : threshold for this pattern\n",
    "#     output:\n",
    "#         position : list right angle position for this pattern on the image\n",
    "\n",
    "#     \"\"\"\n",
    "#     position = []  # Variable output\n",
    "#     # List of match\n",
    "#     res = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "#     for pos in zip(*np.where(res >= threshold)[::-1]):\n",
    "#         position.append(pos)\n",
    "#     return(position)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "class NormalSeatNoCL(pipeline.Process):\n",
    "    process_desc = \"OpenCV4.1.2.30 -> pattern matching \" \\\n",
    "                   \"for seat without colors or letters\"\n",
    "    \n",
    "    @pipeline.overrides\n",
    "    def run(self, image: Iterable, json, threshold) -> None:\n",
    "        position = []  # Variable output\n",
    "        # List of match\n",
    "        res = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "        for pos in zip(*np.where(res >= threshold)[::-1]):\n",
    "            position.append(pos)\n",
    "        json[\"normal_seat\"]= position\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "SVG(url='https://cdn.seatguru.com/en_US/img/20200108203441/seatguru/airlines_new/Aer_Lingus/Aer_Lingus_Airbus_A330-200.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-40-cf2f5da224f8>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-cf2f5da224f8>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class BlackWhite(pipeline.Preprocess):\n",
    "    process_desc = \"OpenCV4.1.2.30 -> rgb to grey\"\n",
    "    \n",
    "    def run(self, image: Iterable) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def Coucoutest(image):\n",
    "    ImageUtil(image).to_gray()\n",
    "    #cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test_img = cv.imread(\"/data/git-clone/ProjetInterpromo2020G8/Oman_Air_Boeing_737-700_new_plane686.jpg\")\n",
    "plt.figure(figsize=(20,40))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celya_Marcelo_notebook.ipynb\t\t  __pycache__\r\n",
      "Charlotte_Marque_notebook.ipynb\t\t  README.md\r\n",
      "Chloe_Gaussail_notebook.ipynb\t\t  requirements.txt\r\n",
      "Hadda_Hassan_notebook.ipynb\t\t  SEATGURU_COMPLETE_INFO.csv\r\n",
      "Image_lignes.csv\t\t\t  Sofiane_Benhamouche_notebook.ipynb\r\n",
      "images\t\t\t\t\t  Sonia_Bezombes_notebook.ipynb\r\n",
      "Jason_Daurat_notebook.ipynb\t\t  Theo_Vedis_notebook.ipynb\r\n",
      "LAYOUT_SEATGURU\t\t\t\t  tuto_git_base.pdf\r\n",
      "Notebook_Rendu.ipynb\t\t\t  Vincent-Nam_Dang_notebook.ipynb\r\n",
      "Oman_Air_Boeing_737-700_new_plane686.jpg  William_Azzouza_notebook.ipynb\r\n",
      "pipeline.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'image_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2a1b9edb0661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCoucoutest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2b235f125cb1>\u001b[0m in \u001b[0;36mCoucoutest\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCoucoutest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mImageUtil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#cv.cvtColor(image, cv.COLOR_BGR2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'image_name'"
     ]
    }
   ],
   "source": [
    "Coucoutest(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f22f18716d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
